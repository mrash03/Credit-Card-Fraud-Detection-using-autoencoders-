{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-09-12T07:08:40.018539Z",
     "iopub.status.busy": "2025-09-12T07:08:40.018054Z",
     "iopub.status.idle": "2025-09-12T07:08:40.278420Z",
     "shell.execute_reply": "2025-09-12T07:08:40.277700Z",
     "shell.execute_reply.started": "2025-09-12T07:08:40.018509Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-12T07:08:42.878233Z",
     "iopub.status.busy": "2025-09-12T07:08:42.877630Z",
     "iopub.status.idle": "2025-09-12T07:08:45.185602Z",
     "shell.execute_reply": "2025-09-12T07:08:45.184901Z",
     "shell.execute_reply.started": "2025-09-12T07:08:42.878209Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "import os, glob, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (roc_auc_score, precision_recall_curve, \n",
    "                             average_precision_score, f1_score, precision_score,\n",
    "                             recall_score, confusion_matrix, classification_report)\n",
    "from sklearn.svm import OneClassSVM\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available(): torch.cuda.manual_seed_all(SEED)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-12T07:08:49.383264Z",
     "iopub.status.busy": "2025-09-12T07:08:49.382450Z",
     "iopub.status.idle": "2025-09-12T07:08:52.228280Z",
     "shell.execute_reply": "2025-09-12T07:08:52.227588Z",
     "shell.execute_reply.started": "2025-09-12T07:08:49.383237Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "files = glob.glob('/kaggle/input/**/creditcard*.csv', recursive=True)\n",
    "if len(files)==0: raise FileNotFoundError(\"Upload 'Credit Card Fraud Detection' dataset\")\n",
    "data_path = files[0]\n",
    "df = pd.read_csv(data_path)\n",
    "print(\"Shape:\", df.shape)\n",
    "display(df.head())\n",
    "print(df['Class'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-12T07:09:10.108967Z",
     "iopub.status.busy": "2025-09-12T07:09:10.108619Z",
     "iopub.status.idle": "2025-09-12T07:09:10.257531Z",
     "shell.execute_reply": "2025-09-12T07:09:10.256714Z",
     "shell.execute_reply.started": "2025-09-12T07:09:10.108931Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "X = df.drop('Class', axis=1)\n",
    "y = df['Class'].values\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X[['Time','Amount']] = scaler.fit_transform(X[['Time','Amount']])\n",
    "X = X.values.astype(np.float32)\n",
    "y = y.astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-12T07:09:12.847662Z",
     "iopub.status.busy": "2025-09-12T07:09:12.847385Z",
     "iopub.status.idle": "2025-09-12T07:09:13.112665Z",
     "shell.execute_reply": "2025-09-12T07:09:13.112051Z",
     "shell.execute_reply.started": "2025-09-12T07:09:12.847639Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=SEED)\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_val, y_train_val, test_size=0.25, stratify=y_train_val, random_state=SEED)\n",
    "\n",
    "X_train_norm = X_train[y_train==0]  # Only normal for AE training\n",
    "print(\"Train (normals) shape:\", X_train_norm.shape)\n",
    "print(\"Val shape:\", X_val.shape, \"Test shape:\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-12T07:09:28.677640Z",
     "iopub.status.busy": "2025-09-12T07:09:28.677116Z",
     "iopub.status.idle": "2025-09-12T07:09:28.691787Z",
     "shell.execute_reply": "2025-09-12T07:09:28.691030Z",
     "shell.execute_reply.started": "2025-09-12T07:09:28.677615Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1024\n",
    "train_loader = DataLoader(TensorDataset(torch.from_numpy(X_train_norm)),\n",
    "                          batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(TensorDataset(torch.from_numpy(X_val), torch.from_numpy(y_val)),\n",
    "                        batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(TensorDataset(torch.from_numpy(X_test), torch.from_numpy(y_test)),\n",
    "                         batch_size=BATCH_SIZE, shuffle=False)\n",
    "input_dim = X.shape[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-12T07:09:32.007705Z",
     "iopub.status.busy": "2025-09-12T07:09:32.007136Z",
     "iopub.status.idle": "2025-09-12T07:09:32.187968Z",
     "shell.execute_reply": "2025-09-12T07:09:32.187363Z",
     "shell.execute_reply.started": "2025-09-12T07:09:32.007677Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class DenoisingAutoencoder(nn.Module):\n",
    "    def __init__(self, input_dim, latent_dim=16):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, latent_dim)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, input_dim)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        z = self.encoder(x)\n",
    "        x_hat = self.decoder(z)\n",
    "        return x_hat\n",
    "\n",
    "model = DenoisingAutoencoder(input_dim=input_dim, latent_dim=16).to(device)\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-12T07:09:37.277488Z",
     "iopub.status.busy": "2025-09-12T07:09:37.277022Z",
     "iopub.status.idle": "2025-09-12T07:11:14.861914Z",
     "shell.execute_reply": "2025-09-12T07:11:14.861266Z",
     "shell.execute_reply.started": "2025-09-12T07:09:37.277462Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def train_denoising_ae(model, train_loader, val_normal, epochs=100, lr=1e-3, \n",
    "                       noise_factor=0.05, patience=10):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.MSELoss()\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min',\n",
    "                                                           factor=0.5, patience=5, verbose=True)\n",
    "    best_val_loss = np.inf\n",
    "    epochs_no_improve = 0\n",
    "    best_state = None\n",
    "\n",
    "    for epoch in range(1, epochs+1):\n",
    "        model.train()\n",
    "        train_losses = []\n",
    "        for batch in train_loader:\n",
    "            x = batch[0].to(device)\n",
    "            x_noisy = x + noise_factor*torch.randn_like(x)\n",
    "            x_hat = model(x_noisy)\n",
    "            loss = criterion(x_hat, x)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_losses.append(loss.item())\n",
    "        avg_train_loss = np.mean(train_losses)\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            x_val = val_normal.to(device)\n",
    "            x_val_hat = model(x_val)\n",
    "            val_loss = criterion(x_val_hat, x_val).item()\n",
    "\n",
    "        scheduler.step(val_loss)\n",
    "        print(f\"Epoch {epoch:02d} | Train loss {avg_train_loss:.6f} | Val loss {val_loss:.6f}\")\n",
    "\n",
    "        if val_loss < best_val_loss - 1e-6:\n",
    "            best_val_loss = val_loss\n",
    "            best_state = {k: v.cpu() for k,v in model.state_dict().items()}\n",
    "            epochs_no_improve = 0\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            if epochs_no_improve >= patience:\n",
    "                print(\"Early stopping.\")\n",
    "                break\n",
    "\n",
    "    if best_state is not None:\n",
    "        model.load_state_dict(best_state)\n",
    "    return model\n",
    "\n",
    "val_normal_tensor = torch.from_numpy(X_val[y_val==0]).float()\n",
    "model = train_denoising_ae(model, train_loader, val_normal_tensor, epochs=100, lr=1e-3, patience=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-12T07:12:13.134579Z",
     "iopub.status.busy": "2025-09-12T07:12:13.133850Z",
     "iopub.status.idle": "2025-09-12T07:12:13.975779Z",
     "shell.execute_reply": "2025-09-12T07:12:13.975225Z",
     "shell.execute_reply.started": "2025-09-12T07:12:13.134556Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def reconstruction_errors(model, dataloader):\n",
    "    model.eval()\n",
    "    errors, labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            if len(batch)==2: x, yb = batch\n",
    "            else: x = batch[0]; yb = None\n",
    "            x = x.to(device).float()\n",
    "            x_hat = model(x)\n",
    "            se = torch.mean((x - x_hat)**2, dim=1).cpu().numpy()\n",
    "            errors.append(se)\n",
    "            if yb is not None: labels.append(yb.numpy())\n",
    "    errors = np.concatenate(errors)\n",
    "    labels = np.concatenate(labels) if len(labels) else None\n",
    "    return errors, labels\n",
    "\n",
    "val_errors, val_labels = reconstruction_errors(model, val_loader)\n",
    "test_errors, test_labels = reconstruction_errors(model, test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-12T07:12:22.028058Z",
     "iopub.status.busy": "2025-09-12T07:12:22.027352Z",
     "iopub.status.idle": "2025-09-12T07:12:27.350828Z",
     "shell.execute_reply": "2025-09-12T07:12:27.349935Z",
     "shell.execute_reply.started": "2025-09-12T07:12:22.028032Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "best_f1, best_thresh = 0, 0\n",
    "for t in np.linspace(min(val_errors), max(val_errors), 200):\n",
    "    preds = (val_errors >= t).astype(int)\n",
    "    f1 = f1_score(val_labels, preds, zero_division=0)\n",
    "    if f1 > best_f1:\n",
    "        best_f1, best_thresh = f1, t\n",
    "\n",
    "threshold = best_thresh\n",
    "print(f\"Best threshold: {threshold:.6e}, with F1: {best_f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-12T07:14:12.387445Z",
     "iopub.status.busy": "2025-09-12T07:14:12.387143Z",
     "iopub.status.idle": "2025-09-12T07:14:12.615219Z",
     "shell.execute_reply": "2025-09-12T07:14:12.614653Z",
     "shell.execute_reply.started": "2025-09-12T07:14:12.387422Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "test_preds = (test_errors >= threshold).astype(int)\n",
    "roc = roc_auc_score(test_labels, test_errors)\n",
    "pr = average_precision_score(test_labels, test_errors)\n",
    "prec_t = precision_score(test_labels, test_preds, zero_division=0)\n",
    "rec_t = recall_score(test_labels, test_preds, zero_division=0)\n",
    "f1_t = f1_score(test_labels, test_preds, zero_division=0)\n",
    "cm = confusion_matrix(test_labels, test_preds)\n",
    "print(f\"Test ROC-AUC: {roc:.4f}, PR-AUC: {pr:.4f}\")\n",
    "print(f\"Precision: {prec_t:.4f}, Recall: {rec_t:.4f}, F1: {f1_t:.4f}\")\n",
    "print(\"Confusion matrix:\\n\", cm)\n",
    "print(classification_report(test_labels, test_preds, digits=4, zero_division=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    latent_train = model.encoder(torch.from_numpy(X_train_norm).to(device)).cpu().numpy()\n",
    "    latent_test = model.encoder(torch.from_numpy(X_test).to(device)).cpu().numpy()\n",
    "\n",
    "ocsvm = OneClassSVM(nu=0.05, kernel='rbf', gamma='scale')\n",
    "ocsvm.fit(latent_train)\n",
    "svm_preds = ocsvm.predict(latent_test)\n",
    "svm_preds = np.where(svm_preds==-1,1,0)\n",
    "\n",
    "roc_svm = roc_auc_score(test_labels, svm_preds)\n",
    "pr_svm = average_precision_score(test_labels, svm_preds)\n",
    "print(f\"OCSVM on latent space - ROC-AUC: {roc_svm:.4f}, PR-AUC: {pr_svm:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-12T07:28:32.398239Z",
     "iopub.status.busy": "2025-09-12T07:28:32.397990Z",
     "iopub.status.idle": "2025-09-12T07:28:32.650750Z",
     "shell.execute_reply": "2025-09-12T07:28:32.649971Z",
     "shell.execute_reply.started": "2025-09-12T07:28:32.398222Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "\n",
    "plt.hist(\n",
    "    test_errors[test_labels==1],\n",
    "    bins=50,\n",
    "    histtype='step',      \n",
    "    linewidth=2.5,\n",
    "    color='orange',\n",
    "    label='fraud'\n",
    ")\n",
    "\n",
    "# draw normal on top (filled but semi-transparent)\n",
    "plt.hist(\n",
    "    test_errors[test_labels==0],\n",
    "    bins=50,\n",
    "    alpha=0.4,\n",
    "    color='blue',\n",
    "    label='normal'\n",
    ")\n",
    "\n",
    "# draw threshold line\n",
    "plt.axvline(threshold, color='k', linestyle='--', linewidth=2, label='threshold')\n",
    "\n",
    "plt.title(\"Reconstruction Error Distribution (Test)\")\n",
    "plt.xlabel(\"Reconstruction error\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 310,
     "sourceId": 23498,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
